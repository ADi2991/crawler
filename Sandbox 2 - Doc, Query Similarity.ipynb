{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.stem.porter as porter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tf-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_headers = [column for column in data.columns if 'Document' in column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ntc_normalize(tf, df):\n",
    "    vecs = tf.copy()\n",
    "    norm_doc_freq = np.log(len(vecs.columns)/df)\n",
    "    # tf.df\n",
    "    vecs = vecs.multiply(norm_doc_freq, axis='rows')\n",
    "    # Cosine normalization:\n",
    "    sum_sq = np.sum(vecs**2, axis=0)\n",
    "    vecs = vecs/sum_sq\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnc_normalize(tf, df):\n",
    "    vecs = tf.copy()\n",
    "    norm_doc_freq = df\n",
    "    # tf.df\n",
    "    vecs = vecs.multiply(norm_doc_freq, axis='rows')\n",
    "    # Cosine normalization:\n",
    "    sum_sq = np.sum(vecs**2, axis=0)\n",
    "    vecs = vecs/sum_sq\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_tokenized_query(query):\n",
    "    stemmer = porter.PorterStemmer(mode='ORIGINAL_ALGORITHM')\n",
    "    #get tokenized words from query\n",
    "    words = word_tokenize(query)\n",
    "    #get stemmed words from query\n",
    "    words = list(map(stemmer.stem, words))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_series is the series of words in our data, i.e data['word']\n",
    "def get_query_tf(query, word_series):\n",
    "    tf = word_series.copy()\n",
    "    words = get_stemmed_tokenized_query(query)\n",
    "    #count the occurences\n",
    "    freq = Counter(words)\n",
    "    #set the value as the count if it exists, else 0\n",
    "    tf = tf.transform(lambda word: freq[word] if word in freq else 0)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tf = get_query_tf(\"I enjoy the fall content\", data['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_query = nnc_normalize(query_tf, data['df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vecs = ntc_normalize(data[doc_headers], data['df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_scores(norm_docs, norm_query):\n",
    "    cosine_prod = norm_vecs.multiply(norm_query, axis=0)\n",
    "    return cosine_prod.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_similarity_scores(norm_vecs, norm_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document 16'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index of maximum, which is our most similar document\n",
    "scores.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document 1     0.000089\n",
       "Document 2     0.000006\n",
       "Document 3     0.000000\n",
       "Document 4     0.000000\n",
       "Document 5     0.000000\n",
       "Document 6     0.000042\n",
       "Document 7     0.000029\n",
       "Document 8     0.000012\n",
       "Document 9     0.000136\n",
       "Document 10    0.000054\n",
       "Document 11    0.000189\n",
       "Document 12    0.000094\n",
       "Document 13    0.000102\n",
       "Document 14    0.000000\n",
       "Document 15    0.000000\n",
       "Document 16    0.000220\n",
       "Document 17    0.000072\n",
       "Document 18    0.000058\n",
       "Document 19    0.000057\n",
       "Document 20    0.000081\n",
       "Document 21    0.000097\n",
       "Document 22    0.000073\n",
       "Document 23    0.000075\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_previews = pd.read_csv('title_preview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_previews = titles_previews.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_previews['title'] = titles_previews['title'].apply(lambda word: word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(string, words):\n",
    "    intersection = [word for word in words if word in string]\n",
    "    return 0.25 if len(intersection)>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_by_title(scores, titles_previews, query_words):\n",
    "    modif = scores.copy()\n",
    "    titles = titles_previews['title'].copy()\n",
    "    titles.index = modif.index\n",
    "    titles = titles.transform(lambda string: get_score(string, words))\n",
    "    return titles+modif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_words = get_stemmed_tokenized_query(\"I enjoy the fall content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'enjoi', 'the', 'fall', 'content']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document 1     0.000089\n",
       "Document 2     0.000006\n",
       "Document 6     0.000042\n",
       "Document 7     0.000029\n",
       "Document 8     0.000012\n",
       "Document 9     0.000136\n",
       "Document 10    0.000054\n",
       "Document 11    0.000189\n",
       "Document 12    0.000094\n",
       "Document 13    0.000102\n",
       "Document 16    0.000220\n",
       "Document 17    0.000072\n",
       "Document 18    0.000058\n",
       "Document 19    0.000057\n",
       "Document 20    0.000081\n",
       "Document 21    0.000097\n",
       "Document 22    0.000073\n",
       "Document 23    0.000075\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores.values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-620cc5fb5b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitles_previews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "for i in titles_previews.values:\n",
    "    print(\"%s\\n%s\\n\" % (i[0],i[1], i[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
